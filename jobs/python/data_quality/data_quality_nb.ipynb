{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import json\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DataQuality\").getOrCreate()\n",
    "\n",
    "print(\"Data Quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções de qualidade de dados\n",
    "def check_nulls(df, columns):\n",
    "    null_counts = df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in columns]).collect()[0]\n",
    "    nulls = {col: count for col, count in zip(columns, null_counts) if count > 0}\n",
    "    if nulls:\n",
    "        raise ValueError(f\"Null values found: {nulls}\")\n",
    "    else:\n",
    "        print(\"Sem linhas Null ✅\")\n",
    "\n",
    "def check_duplicates(df, columns):\n",
    "    duplicate_count = df.groupBy(columns).count().filter(\"count > 1\").count()\n",
    "    if duplicate_count > 0:\n",
    "        raise ValueError(f\"Found {duplicate_count} duplicate rows.\")\n",
    "    else:\n",
    "        print(\"Sem duplicatas ✅\")\n",
    "\n",
    "def count_more_than_zero(data):\n",
    "    \"\"\"\n",
    "    Verifica se o JSON retornado contém ao menos uma entrada.\n",
    "    \n",
    "    :param data: Lista de dados extraídos do JSON\n",
    "    :raises ValueError: Se o JSON estiver vazio.\n",
    "    \"\"\"\n",
    "    if not data or len(data) == 0:\n",
    "        raise ValueError(\"O JSON retornado está vazio, não contém entradas.\")    \n",
    "    else:\n",
    "        print(\"Json Não Vazio ✅\")\n",
    "\n",
    "def check_json_structure(data, expected_keys):\n",
    "    if isinstance(data, list):\n",
    "        for entry in data:\n",
    "            if not all(key in entry for key in expected_keys):\n",
    "                raise ValueError(f\"JSON structure mismatch: {entry}\")\n",
    "        print(\"Formato Json Válido ✅\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid JSON format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para rodar as verificações de qualidade de dados\n",
    "def run_data_quality_checks(**kwargs):\n",
    "\n",
    "    try:\n",
    "        spark = SparkSession.builder.appName(\"DataQuality\").getOrCreate()\n",
    "        \n",
    "        # Carregar dados da camada bronze\n",
    "        bronze_path = '/opt/airflow/bronze_layer/breweries_raw.json'\n",
    "        \n",
    "        # Lendo o arquivo JSON bruto\n",
    "        with open(bronze_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Verificar estrutura do JSON\n",
    "        expected_keys = [\n",
    "            \"id\",\n",
    "            \"name\",\n",
    "            \"brewery_type\",\n",
    "            \"address_1\",\n",
    "            \"address_2\",\n",
    "            \"address_3\",\n",
    "            \"city\",\n",
    "            \"state_province\",\n",
    "            \"postal_code\",\n",
    "            \"country\",\n",
    "            \"longitude\",\n",
    "            \"latitude\",\n",
    "            \"phone\",\n",
    "            \"website_url\",\n",
    "            \"state\",\n",
    "            \"street\"\n",
    "            ]\n",
    "        check_json_structure(data, expected_keys)\n",
    "        count_more_than_zero(data)\n",
    "        \n",
    "        # Carregar dados no Spark DataFrame\n",
    "        df = spark.read.json(bronze_path)\n",
    "\n",
    "        check_nulls(df, [\"name\", \"city\", \"state\"])\n",
    "        check_duplicates(df, [\"id\"])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Data Quality Check Failed: {e}\")\n",
    "        raise \n",
    "    \n",
    "    finally:\n",
    "        spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
